{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs4\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import getpass\n",
    "import easygui as eg\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click(x):\n",
    "    button = driver.find_element(By.XPATH, x)\n",
    "    button.click()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scraping from stepstone"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scraping from stepstone.de to get page source of the job results pages (page 1, page 2, page 3, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_pages(url):\n",
    "    search_result = []\n",
    "    options = Options()\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('user-agent=fake-useragent')\n",
    "    driver.get(url)\n",
    "    time.sleep(6)\n",
    "    ok1 = \"/html/body/div[10]/section/div/section/div[2]/div[1]/div[2]/div\"\n",
    "    ok2 = \"/html/body/div[9]/section/div/section/div[2]/div[1]/div[2]/div\"\n",
    "    ok3 = \"/html/body/div[10]/section/div/section/div[2]/div[1]/div[2]\"\n",
    "    try:\n",
    "        click(ok1)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        click(ok2)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        click(ok3)\n",
    "    except:\n",
    "        pass\n",
    "    npage = \"/html/body/div[4]/div[1]/div/div/div[2]/div/div[2]/div[3]/div/nav/ul/li[9]/a\"\n",
    "    html = driver.page_source\n",
    "    a = 0\n",
    "    while a<20:\n",
    "        search_result.append(html)\n",
    "        time.sleep(1)\n",
    "        i = 0\n",
    "        while i < 4:\n",
    "            driver.execute_script(\"window.scrollTo(0, window.scrollY + 1500)\") \n",
    "            time.sleep(.2)\n",
    "            i+=1\n",
    "        time.sleep(4)\n",
    "        click(npage)\n",
    "        html = driver.page_source\n",
    "        a += 1\n",
    "    return search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result_1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\"https://www.stepstone.de/jobs/python-data-analyst\",\"https://www.stepstone.de/jobs/sql-data-analyst\",\"https://www.stepstone.de/jobs/tableau-data-analyst\",\"https://www.stepstone.de/jobs/tableau-business-intelligence\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdima\\AppData\\Local\\Temp\\ipykernel_8736\\3414772495.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "search_result_1.extend(scrape_pages(urls[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:11<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "(2000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.stepstone.de/stellenangebote--Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.stepstone.de/stellenangebote--Date...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.stepstone.de/stellenangebote--Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.stepstone.de/stellenangebote--Web-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.stepstone.de/stellenangebote--Data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             job_url\n",
       "0  https://www.stepstone.de/stellenangebote--Data...\n",
       "1  https://www.stepstone.de/stellenangebote--Date...\n",
       "2  https://www.stepstone.de/stellenangebote--Data...\n",
       "3  https://www.stepstone.de/stellenangebote--Web-...\n",
       "4  https://www.stepstone.de/stellenangebote--Data..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_url_1 = []\n",
    "for h in tqdm(search_result_1):\n",
    "    soup = bs4(h)\n",
    "    res = soup.find_all(\"article\",{\"class\":\"resultlist-1jx3vjx\"})\n",
    "    for r in res:\n",
    "        href = r.find(\"a\",{\"class\":\"resultlist-1uvdp0v\"}).get(\"href\")\n",
    "        href = \"https://www.stepstone.de\"+href\n",
    "        job_url_1.append(href)\n",
    "df_1 = pd.DataFrame(columns = [\"job_url\"])\n",
    "df_1[\"job_url\"] = job_url_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.drop_duplicates(subset = \"job_url\").reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_1.to_csv(\"job url 1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_1 = pd.read_csv(\"job url 1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_source(df_url):\n",
    "    source = []\n",
    "    job_url = df_url[\"job_url\"].tolist()\n",
    "    options = Options()\n",
    "    # installing chromedriver, so that we dont need to keep the chromedriver file\n",
    "    # that needs to be updated every once in a while. better install the latest automatically\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    for i in job_url: # get full page source for each job offer page\n",
    "        # options.add_argument(\"--disable-notifications\")\n",
    "        # to prevent from being spotted as a robot\n",
    "        options.add_argument('--disable-gpu')\n",
    "        options.add_argument('user-agent=fake-useragent')\n",
    "        # opens the browser, maximize window size\n",
    "        # opening url\n",
    "        driver.get(i)\n",
    "        time.sleep(3.5)\n",
    "        page = driver.page_source\n",
    "        source.append(page)\n",
    "    # saving source column separately for each splitted file\n",
    "    job_source = pd.DataFrame(columns = [\"job_source\"])\n",
    "    job_source[\"job_source\"] = source\n",
    "    filename = \"job source 1.csv\"\n",
    "    job_source.to_csv(filename, index = False)\n",
    "    return job_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdima\\AppData\\Local\\Temp\\ipykernel_8736\\1429130885.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "source = get_page_source(df_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting some details from each page source we had from the big scraping job (see cell above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stepstone = pd.DataFrame()\n",
    "url_1,d_1,t_1,cn_1,cl_1,c_1= [],[],[],[],[],[]\n",
    "\n",
    "df1 = df_1.copy()\n",
    "df2 = source.copy()\n",
    "description_1,title_1,comp_name_1,comp_url_1,city_1 = [],[],[],[],[]\n",
    "source = df2[\"job_source\"].tolist()\n",
    "for s in source:\n",
    "    soup = bs4(s, \"html.parser\")\n",
    "    try:\n",
    "        jobtitle = soup.find(\"span\",{\"data-at\":\"header-job-title\"}).text\n",
    "    except:\n",
    "        jobtitle = \"unknown\"\n",
    "    title_1.append(jobtitle)\n",
    "    try:\n",
    "        compname = soup.find(\"a\",{\"data-at\":\"header-company-name\"}).text\n",
    "    except:\n",
    "        compname = \"unknown\"\n",
    "    comp_name_1.append(compname)\n",
    "    try:\n",
    "        complink = soup.find(\"a\",{\"data-at\":\"header-company-name\"}).get(\"href\")\n",
    "    except:\n",
    "        complink = \"unknown\"\n",
    "    comp_url_1.append(complink)\n",
    "    try:\n",
    "        city = soup.find(\"span\",{\"class\":\"listing-content-provider-1u79rpn\"}).text\n",
    "    except:\n",
    "        city = \"unknown\"\n",
    "    city_1.append(city)\n",
    "    infotext = soup.find_all(\"div\",{\"class\":\"listing-content-provider-10ltcrf\"})\n",
    "    desc = []\n",
    "    for i in infotext:\n",
    "        try:\n",
    "            texts = i.find_all(\"p\")\n",
    "            for t in texts:\n",
    "                info = t.text\n",
    "                desc.append(info)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            texts = i.find_all(\"li\")\n",
    "            for t in texts:\n",
    "                info = t.text\n",
    "                desc.append(info)\n",
    "        except:\n",
    "            pass\n",
    "    # enemy spotted\n",
    "    description = \" \".join(desc).replace(\"\\xa0\",\"\").replace(\"\\\\n\",\"\")\n",
    "    description_1.append(description)\n",
    "d_1.extend(description_1)\n",
    "t_1.extend(title_1)\n",
    "cn_1.extend(comp_name_1)\n",
    "cl_1.extend(comp_url_1)\n",
    "c_1.extend(city_1)\n",
    "url_1.extend(df1[\"job_url\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(939, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_url</th>\n",
       "      <th>description</th>\n",
       "      <th>job_title</th>\n",
       "      <th>comp_name</th>\n",
       "      <th>comp_link</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.stepstone.de/stellenangebote--Data...</td>\n",
       "      <td>Step out of your comfort zone, excel and redef...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>ZEISS</td>\n",
       "      <td>https://www.stepstone.de/cmp/de/ZEISS-3427/job...</td>\n",
       "      <td>Oberkochen (Baden-Württemberg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.stepstone.de/stellenangebote--Date...</td>\n",
       "      <td>Die parcIT ist einer der führenden Anbieter vo...</td>\n",
       "      <td>Datenanalyst / Data Analyst Risikomanagement (...</td>\n",
       "      <td>parcIT GmbH</td>\n",
       "      <td>https://www.stepstone.de/cmp/de/parcIT-GmbH-78...</td>\n",
       "      <td>Köln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.stepstone.de/stellenangebote--Data...</td>\n",
       "      <td>Die Vonovia SE ist Europas führendes privates ...</td>\n",
       "      <td>Data Analyst (m/w/d) im BI-Controlling</td>\n",
       "      <td>Vonovia</td>\n",
       "      <td>https://www.stepstone.de/cmp/de/Vonovia-76597/...</td>\n",
       "      <td>Bochum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.stepstone.de/stellenangebote--Web-...</td>\n",
       "      <td>Die SCHUFA war schon Fintech, bevor es Fintech...</td>\n",
       "      <td>Web &amp; Data Analyst (w/m/d) in Voll- oder Teilz...</td>\n",
       "      <td>SCHUFA Holding AG</td>\n",
       "      <td>https://www.stepstone.de/cmp/de/SCHUFA-Holding...</td>\n",
       "      <td>Wiesbaden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.stepstone.de/stellenangebote--Data...</td>\n",
       "      <td>Analyse, Aufbereitung und Bewertung verkehrsp...</td>\n",
       "      <td>Data Analyst*in - Verkehrsforschung</td>\n",
       "      <td>DSW21 Dortmunder Stadtwerke AG</td>\n",
       "      <td>https://www.stepstone.de/cmp/de/DSW21-Dortmund...</td>\n",
       "      <td>Dortmund</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             job_url  \\\n",
       "0  https://www.stepstone.de/stellenangebote--Data...   \n",
       "1  https://www.stepstone.de/stellenangebote--Date...   \n",
       "2  https://www.stepstone.de/stellenangebote--Data...   \n",
       "3  https://www.stepstone.de/stellenangebote--Web-...   \n",
       "4  https://www.stepstone.de/stellenangebote--Data...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Step out of your comfort zone, excel and redef...   \n",
       "1  Die parcIT ist einer der führenden Anbieter vo...   \n",
       "2  Die Vonovia SE ist Europas führendes privates ...   \n",
       "3  Die SCHUFA war schon Fintech, bevor es Fintech...   \n",
       "4   Analyse, Aufbereitung und Bewertung verkehrsp...   \n",
       "\n",
       "                                           job_title  \\\n",
       "0                                            unknown   \n",
       "1  Datenanalyst / Data Analyst Risikomanagement (...   \n",
       "2             Data Analyst (m/w/d) im BI-Controlling   \n",
       "3  Web & Data Analyst (w/m/d) in Voll- oder Teilz...   \n",
       "4                Data Analyst*in - Verkehrsforschung   \n",
       "\n",
       "                        comp_name  \\\n",
       "0                           ZEISS   \n",
       "1                     parcIT GmbH   \n",
       "2                         Vonovia   \n",
       "3               SCHUFA Holding AG   \n",
       "4  DSW21 Dortmunder Stadtwerke AG   \n",
       "\n",
       "                                           comp_link  \\\n",
       "0  https://www.stepstone.de/cmp/de/ZEISS-3427/job...   \n",
       "1  https://www.stepstone.de/cmp/de/parcIT-GmbH-78...   \n",
       "2  https://www.stepstone.de/cmp/de/Vonovia-76597/...   \n",
       "3  https://www.stepstone.de/cmp/de/SCHUFA-Holding...   \n",
       "4  https://www.stepstone.de/cmp/de/DSW21-Dortmund...   \n",
       "\n",
       "                             city  \n",
       "0  Oberkochen (Baden-Württemberg)  \n",
       "1                            Köln  \n",
       "2                          Bochum  \n",
       "3                       Wiesbaden  \n",
       "4                        Dortmund  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stepstone[\"job_url\"] = url_1\n",
    "df_stepstone[\"description\"] = d_1\n",
    "df_stepstone[\"job_title\"] = t_1\n",
    "df_stepstone[\"comp_name\"] = cn_1\n",
    "df_stepstone[\"comp_link\"] = cl_1\n",
    "df_stepstone[\"city\"] = c_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(939, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(906, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_stepstone = df_stepstone[df_stepstone[\"description\"] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stepstone.to_csv(\"stepstone 1 incomplete.csv\", index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now scrape from indeed.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_indeed(key):    \n",
    "    url2 = \"https://de.indeed.com/?r=us\"\n",
    "    options = Options()\n",
    "    # options.add_argument(\"--disable-notifications\")\n",
    "    # to prevent from being spotted as a robot\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('user-agent=fake-useragent')\n",
    "    # opening url\n",
    "    driver.get(url2)\n",
    "    time.sleep(2)\n",
    "    search_xpath = \"/html/body/div[1]/div[1]/div/span/div[4]/div[2]/div/div/div/div/form/div/div[1]/div/div[1]/div/div[2]/input\"\n",
    "    search = driver.find_element(By.XPATH,search_xpath)\n",
    "\n",
    "    search.send_keys(key)\n",
    "    findjob_xpath = \"/html/body/div[1]/div[1]/div/span/div[4]/div[2]/div/div/div/div/form/button\"\n",
    "    click(findjob_xpath)\n",
    "\n",
    "    html = driver.page_source\n",
    "    npage = \"/html/body/main/div/div[1]/div/div/div[5]/div[1]/nav/div[6]/a\"\n",
    "    lhtml2 = []\n",
    "    counter = 1\n",
    "    a = 0\n",
    "    while a < 30:\n",
    "        if counter == 2:\n",
    "            time.sleep(2)\n",
    "            webdriver.ActionChains(driver).send_keys(Keys.ESCAPE).perform()\n",
    "        lhtml2.append(html)\n",
    "        time.sleep(1)\n",
    "        i = 0\n",
    "        while i < 4:\n",
    "            driver.execute_script(\"window.scrollTo(0, window.scrollY + 1500)\") \n",
    "            time.sleep(.2)\n",
    "            i+=1\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            click(npage)\n",
    "        except:\n",
    "            a = 30\n",
    "        counter += 1\n",
    "        html = driver.page_source\n",
    "        # comparing html_before and html_after\n",
    "        a += 1\n",
    "    return lhtml2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdima\\AppData\\Local\\Temp\\ipykernel_11388\\18862263.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "keys = [\"sql data analyst\",\"python data analyst\",\"tableau data analyst\",\"tableau business intelligence\"]\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "lhtml2 = []\n",
    "for key in keys:\n",
    "    lhtml2.extend(scrape_indeed(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:09<00:00,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1218\n",
      "(1218, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://de.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://de.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://de.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://de.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://de.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             job_url\n",
       "0  https://de.indeed.com/pagead/clk?mo=r&ad=-6NYl...\n",
       "1  https://de.indeed.com/pagead/clk?mo=r&ad=-6NYl...\n",
       "2  https://de.indeed.com/pagead/clk?mo=r&ad=-6NYl...\n",
       "3  https://de.indeed.com/pagead/clk?mo=r&ad=-6NYl...\n",
       "4  https://de.indeed.com/pagead/clk?mo=r&ad=-6NYl..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhref2 = []\n",
    "for h in tqdm(lhtml2):\n",
    "    soup = bs4(h)\n",
    "    container = soup.find(\"ul\",{\"class\":\"jobsearch-ResultsList css-0\"})\n",
    "    res = container.find_all(\"div\",{\"class\":\"slider_container css-g7s71f eu4oa1w0\"})\n",
    "    for r in res:\n",
    "        href = r.find(\"h2\",{\"tabindex\":\"-1\"}).find(\"a\").get(\"href\")\n",
    "        href = \"https://de.indeed.com\" + href\n",
    "        lhref2.append(href)\n",
    "href_pd2 = pd.DataFrame(columns = [\"job_url\"])\n",
    "href_pd2[\"job_url\"] = lhref2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdima\\AppData\\Local\\Temp\\ipykernel_11388\\535041721.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n",
      "100%|██████████| 1218/1218 [1:18:42<00:00,  3.88s/it]\n"
     ]
    }
   ],
   "source": [
    "source2 = []\n",
    "options = Options()\n",
    "# installing chromedriver, so that we dont need to keep the chromedriver file\n",
    "# that needs to be updated every once in a while. better install the latest automatically\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "for i in tqdm(lhref2):\n",
    "    # options.add_argument(\"--disable-notifications\")\n",
    "    # to prevent from being spotted as a robot\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('user-agent=fake-useragent')\n",
    "    # opening url\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    page = driver.page_source\n",
    "    source2.append(page)\n",
    "href_pd2[\"job_source\"] = source2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_url</th>\n",
       "      <th>job_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://de.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>&lt;html dir=\"ltr\" lang=\"de\" class=\"js-focus-visi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             job_url  \\\n",
       "0  https://de.indeed.com/pagead/clk?mo=r&ad=-6NYl...   \n",
       "\n",
       "                                          job_source  \n",
       "0  <html dir=\"ltr\" lang=\"de\" class=\"js-focus-visi...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [00:42<00:00, 28.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1218 1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ldescription2,ltitle2,lcompname2,lcomplink2,lcity2 = [],[],[],[],[]\n",
    "\n",
    "for s in tqdm(source2):\n",
    "    soup = bs4(s, \"html.parser\")\n",
    "    try:\n",
    "        jobtitle = soup.find(\"h1\",{\"class\":\"icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title\"}).text\n",
    "    except:\n",
    "        jobtitle = None\n",
    "    ltitle2.append(jobtitle)\n",
    "    try:\n",
    "        compname = soup.find(\"div\",{\"data-company-name\":\"true\"}).text\n",
    "    except:\n",
    "        compname = None\n",
    "    lcompname2.append(compname)\n",
    "    try:\n",
    "        complink = soup.find(\"div\",{\"data-company-name\":\"true\"}).find(\"a\").get(\"href\")\n",
    "    except:\n",
    "        complink = None\n",
    "    lcomplink2.append(complink)\n",
    "    city = None\n",
    "    lcity2.append(city)\n",
    "    infotext = soup.find(\"div\",{\"id\":\"jobDescriptionText\"}).find_all(\"p\")\n",
    "    desc = []\n",
    "    for i in infotext:\n",
    "        try:\n",
    "            texts = i.find(\"b\").text\n",
    "            desc.append(texts)\n",
    "        except:\n",
    "            texts = i.text\n",
    "        desc.append(texts)\n",
    "    # enemy spotted\n",
    "    description = \" \".join(desc)\n",
    "    ldescription2.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "href_pd2[\"description\"] = ldescription2\n",
    "href_pd2[\"job_title\"] = ltitle2\n",
    "href_pd2[\"comp_name\"] = lcompname2\n",
    "href_pd2[\"comp_link\"] = lcomplink2\n",
    "href_pd2[\"city\"] = lcity2\n",
    "href_pd2.to_csv(\"indeed 1 incomplete.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_url</th>\n",
       "      <th>job_source</th>\n",
       "      <th>description</th>\n",
       "      <th>job_title</th>\n",
       "      <th>comp_name</th>\n",
       "      <th>comp_link</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://de.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>&lt;html dir=\"ltr\" lang=\"de\" class=\"js-focus-visi...</td>\n",
       "      <td>Du entwickelst Algorithmen und Machine Learn...</td>\n",
       "      <td>Data Scientist (gn)</td>\n",
       "      <td>LichtBlick SE</td>\n",
       "      <td>https://de.indeed.com/cmp/Lichtblick-Se?campai...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             job_url  \\\n",
       "0  https://de.indeed.com/pagead/clk?mo=r&ad=-6NYl...   \n",
       "\n",
       "                                          job_source  \\\n",
       "0  <html dir=\"ltr\" lang=\"de\" class=\"js-focus-visi...   \n",
       "\n",
       "                                         description            job_title  \\\n",
       "0    Du entwickelst Algorithmen und Machine Learn...  Data Scientist (gn)   \n",
       "\n",
       "       comp_name                                          comp_link  city  \n",
       "0  LichtBlick SE  https://de.indeed.com/cmp/Lichtblick-Se?campai...  None  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "href_pd2 = pd.read_csv(\"indeed 1 incomplete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "href_pd = pd.read_csv(\"stepstone 1 incomplete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.concat([href_pd, href_pd2], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2124, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1843, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full = full[full[\"description\"] != \"\"]\n",
    "full = full.drop(columns = [\"job_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.to_csv(\"full.csv\", index = False)\n",
    "df = full.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = [\"comp_link\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "querying = [\"data\",\"analy\",\"analy\",\"sql\",\"sql\",\"sql\",\"big data\",\"query\",\"entry\",\"base\",\"warehouse\"] #A\n",
    "engineering = [\"python\",\"python\",\"data\",\"analy\",\"analy\",\"machine\",\"learn\",\"etl\",\"oop\",\"pipe\",\"pipe\",\"tensor\",\"engineer\",\"nlp\"] #B\n",
    "analysis = [\"python\",\"python\",\"python\",\"data\",\"analy\",\"analy\",\"eda\",\"predict\",\"machine\",\"learn\",\"test\",\"explor\",\"statisti\"] #C\n",
    "model_building = [\"python\",\"python\",\"data\",\"analy\",\"analy\",\"machine\",\"machine\",\"learn\",\"predict\",\"ml\",\"model\",\"model\",\"train\"] #D\n",
    "scraping = [\"python\",\"python\",\"python\",\"data\",\"analy\",\"analy\",\"clean\",\"mining\",\"scrap\",\"csv\",\"json\",\"api\"] #E\n",
    "dashboarding = [\"bi\",\"bi\",\"power\",\"data\",\"analy\",\"analy\",\"dashboard\",\"tableau\",\"tableau\",\"tableau\",\"report\",\"visuali\"] #F\n",
    "category = [querying, engineering, analysis, model_building, scraping, dashboarding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A,B,C,D,E,F = [],[],[],[],[],[]\n",
    "\n",
    "scores = [A,B,C,D,E,F]\n",
    "description = df.description.tolist()\n",
    "for des in tqdm(description):\n",
    "    for score, cat in list(zip(scores, category)):\n",
    "        sc = []\n",
    "        for i in cat:\n",
    "            if i in str(des).lower():\n",
    "                sc.append(1)\n",
    "            # else:\n",
    "            #     sc.append(0)\n",
    "        n = len(sc)/len(cat)*100\n",
    "        score.append(round(n,2))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"querying\"] = A\n",
    "df[\"engineering\"] = B\n",
    "df[\"analysis\"] = C\n",
    "df[\"model_building\"] = D\n",
    "df[\"scraping\"] = E\n",
    "df[\"dashboarding\"] = F\n",
    "df = df.fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = []\n",
    "for i in df[\"city\"]:\n",
    "    if \",\" in i:\n",
    "        i= \"multiple cities\"\n",
    "        city.append(i)\n",
    "    else:\n",
    "        city.append(i)\n",
    "df[\"city\"] = city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"job_url\",\"description\",\"comp_link\"])\n",
    "df.to_csv(\"data clean with url.csv\", index = False)\n",
    "X.to_csv(\"data clean.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1acc24bd1901f9ae8c29efb6830fcc1ca9fe0219dd00f8f1dc1b91856def15a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
